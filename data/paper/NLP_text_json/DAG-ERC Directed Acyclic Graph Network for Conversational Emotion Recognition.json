{
    "Abstract": "The modeling of conversational context playsa vital role in emotion recognition from con-versation (ERC). In this paper, we put for-ward a novel idea of encoding the utteranceswith a directed acyclic graph (DAG) to bettermodel the intrinsic structure within a conversa-tion, and design a directed acyclic neural net-work, namely DAG-ERC1, to implement thisidea. In an attempt to combine the strengths ofconventional graph-based neural models andrecurrence-based neural models, DAG-ERCprovides a more intuitive way to model the in-formation flow between long-distance conver-sation background and nearby context. Exten-sive experiments are conducted on four ERCbenchmarks with state-of-the-art models em-ployed as baselines for comparison. The empir-ical results demonstrate the superiority of thisnew model and confirm the motivation of thedirected acyclic graph architecture for ERC.",
    "Keywords": null,
    "Body": [
        "IntroductionUtterance-level emotion recognition in conversa-tion (ERC) is an emerging task that aims to identifythe emotion of each utterance in a conversation.",
        "This task has been recently concerned by a con-siderable number of NLP researchers due to itspotential applications in several areas, such as opin-ion mining in social media (Chatterjee et al., 2019)",
        "and building an emotional and empathetic dialogsystem (Majumder et al., 2020).",
        "The emotion of a query utterance is likely to beinfluenced by many factors such as the utterancesspoken by the same speaker and the surroundingconversation context. Indeed, how to model theconversational context lies at the heart of this task(Poria et al., 2019a). Empirical evidence also shows\u0003Corresponding author.",
        "1The code is available at https://github.com/shenwzh3/DAG-ERCFigure 1: Conversation as a directed acyclic graph,with brown directed edges representing the informationpropagation between speakers and blue ones represent-ing the information propagation inside a same speaker.",
        "that a good representation of conversation contextsignificantly contributes to the model performance,especially when the content of query utterance istoo short to be identified alone (Ghosal et al., 2019).",
        "Numerous efforts have been devoted to the mod-eling of conversation context. Basically, they canbe divided into two categories: graph-based meth-ods (Zhang et al., 2019a; Ghosal et al., 2019; Zhonget al., 2019; Ishiwatari et al., 2020; Shen et al.,2020) and recurrence-based methods (Hazarikaet al., 2018a; Hazarika et al., 2018b; Majumderet al., 2019; Ghosal et al., 2020). For the graph-based methods, they concurrently gather informa-tion of the surrounding utterances within a certainwindow, while neglecting the distant utterancesand the sequential information. For the recurrence-based methods, they consider the distant utterancesand sequential information by encoding the utter-ances temporally. However, they tend to update thequery utterance's state with only relatively limitedinformation from the nearest utterances, makingthem difficult to get a satisfying performance.arXiv:2105.12907v2  [cs.CL]  16 Sep 2021",
        "According to the above analysis, an intuitivelybetter way to solve ERC is to allow the advantagesof graph-based methods and recurrence-based mod-els to complement each other. This can be achievedby regarding each conversation as a directed acyclicgraph (DAG). As illustrated in Figure 1, each ut-terance in a conversation only receives informationfrom some previous utterances and cannot propa-gate information backward to itself and its prede-cessors through any path. This characteristic indi-cates that a conversation can be regarded as a DAG.",
        "Moreover, by the information flow from predeces-sors to successors through edges, DAG can gatherinformation for a query utterance from both theneighboring utterances and the remote utterances,which acts like a combination of graph structureand recurrence structure. Thus, we speculate thatDAG is a more appropriate and reasonable waythan graph-based structure and recurrence-basedstructure to model the conversation context in ERC.",
        "In this paper, we propose a method to model theconversation context in the form of DAG. Firstly,rather than simply connecting each utterance with afixed number of its surrounding utterances to builda graph, we propose a new way to build a DAGfrom the conversation with constraints on speakeridentity and positional relations. Secondly, inspiredby DAGNN (Thost and Chen, 2021), we proposea directed acyclic graph neural network for ERC,namely DAG-ERC. Unlike the traditional graphneural networks such as GCN (Kipf and Welling,2016) and GAT (Veli Ë‡ckovi Â´c et al., 2017) that ag-gregate information from the previous layer, DAG-ERC can recurrently gather information of prede-cessors for every utterance in a single layer, whichenables the model to encode the remote contextwithout having to stack too many layers. Besides,in order to be more applicable to the ERC task, ourDAG-ERC has two improvements over DAGNN:",
        "(1) a relation-aware feature transformation to gatherinformation based on speaker identity and (2) a con-textual information unit to enhance the informationof historical context. We conduct extensive exper-iments on four ERC benchmarks and the resultsshow that the proposed DAG-ERC achieves compa-rable performance with the state-of-the-art models.",
        "Furthermore, several studies are conducted to ex-plore the effect of the proposed DAG structure andthe modules of DAG-ERC.",
        "The contributions of this paper are threefold.",
        "First, we are the first to consider a conversationas a directed acyclic graph in the ERC task. Sec-ond, we propose a method to build a DAG from aconversation with constraints based on the speakeridentity and positional relations. Third, we proposea directed acyclic graph neural network for ERC,which takes DAGNN as its backbone and has twomain improvements designed specifically for ERC.",
        "2 Related work2.1 Emotion Recognition in ConversationRecently, several ERC datasets with textual datahave been released (Busso et al., 2008; Schulleret al., 2012; Zahiri and Choi, 2017; Li et al., 2017;",
        "Chen et al., 2018; Poria et al., 2019b), arousingthe widespread interest of NLP researchers. In thefollowing paragraphs, we divide the related worksinto two categories according to the methods theyuse to model the conversation context.",
        "Graph-based Models DialogGCN (Ghosal et al.,2019) treats each dialog as a graph in which eachutterance is connected with the surrounding utter-ances. RGAT (Ishiwatari et al., 2020) adds posi-tional encodings to DialogGCN. ConGCN (Zhanget al., 2019a) regards both speakers and utterancesas graph nodes and makes the whole ERC dataseta single graph. KET (Zhong et al., 2019) uses hier-archical Transformers (Vaswani et al., 2017) withexternal knowledge. DialogXL (Shen et al., 2020)",
        "improves XLNet (Yang et al., 2019) with enhancedmemory and dialog-aware self-attention.2Recurrence-based Models In this category, ICON(Hazarika et al., 2018a) and CMN (Hazarika et al.,2018b) both utilize gated recurrent unit (GRU) andmemory networks. HiGRU (Jiao et al., 2019) con-tains two GRUs, one for utterance encoder andthe other for conversation encoder. DialogRNN(Majumder et al., 2019) is a recurrence-basedmethod that models dialog dynamics with severalRNNs. COSMIC (Ghosal et al., 2020) is the latestmodel, which adopts a network structure very closeto DialogRNN and adds external commonsenseknowledge to improve performance.",
        "2.2 Directed Acyclic Graph Neural NetworkDirected acyclic graph is a special type of graphstructure that can be seen in multiple areas, forexample, the parsing results of source code (Alla-manis et al., 2018) and logical formulas (Crouse2We regard KET and DialogXL as graph-based modelsbecause they both adopt Transformer in which self-attentioncan be viewed as a fully-connected graph in some sense.",
        "et al., 2019). A number of neural networks that em-ploy DAG architecture have been proposed, suchas Tree-LSTM (Tai et al., 2015), DAG-RNN(Shuaiet al., 2016), D-V AE (Zhang et al., 2019b), andDAGNN (Thost and Chen, 2021). DAGNN is dif-ferent from the previous DAG models in the modelstructure. Specifically, DAGNN allows multiplelayers to be stacked, while the others have onlyone single layer. Besides, instead of merely carry-ing out naive sum or element-wise product on thepredecessors' representations, DAGNN conductsinformation aggregation using graph attention.",
        "3 Methodology3.1 Problem DefinitionIn ERC, a conversation is defined as a sequence ofutterancesfu1;u2;:::;uNg, whereNis the num-ber of utterances. Each utterance uiconsists ofnitokens, namely ui=fwi1;wi2;:::;winig. A dis-crete valueyi2S is used to denote the emotionlabel ofui, whereSis the set of emotion labels.",
        "The speaker identity is denoted by a function p(\u0001).",
        "For example, p(ui)2P denotes the speaker of uiandPis the collection of all speaker roles in anERC dataset. The objective of this task is to predictthe emotion label ytfor a given query utterance utbased on dialog context fu1;u2;:::;uNgand thecorresponding speaker identity.",
        "3.2 Building a DAG from a ConversationWe design a directed acyclic graph (DAG) to modelthe information propagation in a conversation. ADAG is denoted by G= (V;E;R). In this paper,the nodes in the DAG are the utterances in the con-versation, i.e.,V=fu1;u2;:::;uNg, and the edge(i;j;rij)2 E represents the information propa-gated fromuitouj, whererij2R is the relationtype of the edge. The set of relation types of edges,R=f0;1g, contains two types of relation: 1forthat the two connected utterances are spoken by thesame speaker, and 0for otherwise.",
        "We impose three constraints to decide when anutterance would propagate information to another,i.e., when two utterances are connected in the DAG:",
        "Direction:8j > i; (j;i;rji)=2E. A previous ut-terance can pass message to a future utterance, buta future utterance cannot pass message backwards.",
        "Remote information: 9<i;p (u) =p(ui);(;i;ri)2E and8j <; (j;i;rji)=2E. For eachutteranceuiexcept the first one, there is a previousutteranceuthat is spoken by the same speaker asAlgorithm 1 Building a DAG from a ConversationInput: the dialogfu1;u2;:::;uNg, speaker iden-tityp(\u0001), hyper-parameter !",
        "Output:G= (V;E;R)",
        "\u0000115: end while16:end for17:returnG= (V;E;R)",
        "ui. The information generated before uis calledremote information, which is relatively less impor-tant. We assume that when the speaker speaks u,she/he has been aware of the remote informationbeforeu. That means, uhas included the remoteinformation and it will be responsible for propagat-ing the remote information to ui.",
        "Local information: 8l;",
        "Usually, the information of the local context is im-portant. Consider uanduidefined in the secondconstraint. We assume that every utterance ulinbetweenuanduicontains local information, andthey will propagate the local information to ui.",
        "The first constraint ensures the conversation tobe a DAG, and the second and third constraintsindicate that uis the cut-off point of remote andlocal information. We regard uas the!-th latestutterance spoken by p(ui)beforeui, where!isa hyper-parameter. Then for each utterance ulinbetweenuandui, we make a directed edge fromultoui. We show the above process of building aDAG in Algorithm 1.",
        "An example of the DAG is shown in Figure 2.",
        "In general, our DAG has two main advancementscompared to the graph structures developed in pre-vious works (Ghosal et al., 2019; Ishiwatari et al.,2020): First, our DAG doesn't have edges fromfuture utterances to previous utterances, which we",
        "ð‘¢1ð‘¢3ð‘¢6 ð‘¢4 ð‘¢2ð‘¢5Figure 2: An example DAG built from a three-partyconversation, with != 1. The three speakers' utter-ances are colored by red, blue and green, respectively.",
        "Solid lines represent the edges of local information, anddash lines denote the edges of remote information.",
        "argue is more reasonable and realistic, as the emo-tion of a query utterance should not be influencedby the future utterances in practice. Second, ourDAG seeks a more meaningful ufor each utter-ance, rather than simply connecting each utterancewith a fixed number of surrounding utterances.",
        "3.3 Directed Acyclic Graph Neural NetworkIn this section, we introduce the proposed DirectedAcyclic Graph Neural Network for ERC (DAG-ERC). The framework is shown in Figure 3.",
        "3.3.1 Utterance Feature ExtractionDAG-ERC regards each utterance as a graph node,the feature of which can be extracted by a pre-trained Transformer-based language model. Fol-lowing the convention, the pre-trained languagemodel is firstly fine-tuned on each ERC dataset,and its parameters are then frozen while trainingDAG-ERC. Following Ghosal et al. (2020), weemploy RoBERTa-Large (Liu et al., 2019), whichhas the same architecture as BERT-Large (Devlinet al., 2018), as our feature extractor. More specifi-cally, for each utterance ui, we prepend a specialtoken [CLS]to its tokens, making the input a formoff[CLS];wi1;wi2;:::;winig. Then, we use the[CLS]'s pooled embedding at the last layer as thefeature representation of ui.",
        "3.3.2 GNN, RNN and DAGNNBefore introducing the DAG-ERC layers in de-tail, we first briefly describe graph-based mod-els, recurrence-based models and directed acyclicgraph models to help understand their differences.",
        "For each node at each layer, graph-based models(GNN) aggregate the information of its neighboringnodes at the previous layer as follows:",
        "Hli=f(Aggregate (fHl\u00001jjj2Nig);Hl\u00001i);(1)wheref(\u0001)is the information processing function,Aggregate (\u0001)is the information aggregation func-tion to gather information from neighboring nodes,andNidenotes the neighbours of the i-th node.",
        "Recurrence-based models (RNN) allow infor-mation to propagate temporally at the same layer,while thei-th node only receives information fromthe(i\u00001)-th node:",
        "Directed acyclic graph models (DAGNN) worklike a combination of GNN and RNN. They aggre-gate information for each node in temporal order,and allow all nodes to gather information fromneighbors and update their states at the same layer:",
        "Hli=f(Aggregate (fHljjj2Nig);Hl\u00001i):(3)",
        "The strength of applying DAGNN to ERC isrelatively apparent: By allowing information topropagate temporally at the same layer, DAGNNcan get access to distant utterances and model theinformation flow throughout the whole conversa-tion, which is hardly possible for GNN. Besides,DAGNN gathers information from several neigh-boring utterances, which sounds more appealingthan RNN as the latter only receives informationfrom the (i\u00001)-th utterance.",
        "3.3.3 DAG-ERC LayersOur proposed DAG-ERC is primarily inspired byDAGNN (Thost and Chen, 2021), with novel im-provements specially made for emotion recognitionin conversation. At each layer lof DAG-ERC, dueto the temporal information flow, the hidden stateof utterances should be computed recurrently fromthe first utterance to the last one.",
        "For each utterance ui, the attention weights be-tweenuiand its predecessors are calculated byusingui's hidden state at the (l\u00001)-th layer to at-tend to the predecessors' hidden states at l-th layer:",
        "lij=Softmaxj2N i(Wl[HljkHl\u00001i]) (4)",
        "whereWlare trainable parameters and kdenotesthe concatenation operation.",
        "The information aggregation operation in DAG-ERC is different from that in DAGNN. Instead ofmerely gathering information according to the at-tention weights, inspired by R-GCN (Schlichtkrullet al., 2018), we apply a relation-aware feature",
        "Figure 3: The framework of Directed Acyclic Graph Neural Network for ERC (DAG-ERC).",
        "transformation to make full use of the relationaltype of edges:",
        "Mli=Xj2N iijWlrijHlj; (5)",
        "whereWlrij2fWl0;Wl1gare trainable parametersfor the relation-aware transformation.",
        "After the aggregated information Mliis calcu-lated, we make it interact with ui's hidden state atthe previous layer Hl\u00001ito obtain the final hiddenstate ofuiat the current layer. In DAGNN, the finalhidden state is obtained by allowing Mlito controlinformation propagation of Hl\u00001ito thel-th layerwith a gated recurrent unit (GRU):",
        "eHli=GRUlH(Hl\u00001i;Mli); (6)",
        "whereHl\u00001i,Mli, andeHliare the input, hidden stateand output of the GRU, respectively.",
        "We refer to the process in Equation 6 as nodalinformation unit , because it focuses on the nodeinformation propagating from the past layer to thecurrent layer. Nodal information unit may be suit-able for the tasks that DAGNN is originally de-signed to solve. However, we find that only usingnodal information unit is not enough for ERC, es-pecially when the query utterance ui's emotionshould be derived from its context. The reason isthat in DAGNN, the information of context Mliisonly used to control the propagation of ui's hiddenstate, and under this circumstance, the informationof context is not fully leveraged. Therefore, we de-sign another GRU called contextual informationunit to model the information flow of historicalcontext through a single layer. In the contextualinformation unit, the roles of Hi\u00001iandMliin GRUare reversed, i.e., Hi\u00001icontrols the propagation ofMli:",
        "Cli=GRUlM(Mli;Hl\u00001i): (7)",
        "The representation of uiat thel-th layer is thesum ofeHliandCli:",
        "Hli=eHli+Cli: (8)",
        "3.3.4 Training and PredictionWe take the concatenation of ui's hidden statesat all DAG-ERC layers as the final representationofui, and pass it through a feed-forward neuralnetwork to get the predicted emotion:",
        "Hi=kLl=0Hli; (9)",
        "zi=ReLU (WHHi+bH); (10)",
        "Pi=Softmax (Wzzi+bz); (11)",
        "byi=Argmaxk2S(Pi[k]): (12)",
        "For the training of DAG-ERC, we employ thestandard cross-entropy loss as objective function:",
        "whereMis the number of training conversations,Niis the number of utterances in the i-th conver-sation,yi;tis the ground truth label, and \u0012is thecollection of trainable parameters of DAG-ERC.",
        "Dataset# Conversations # UterrancesTrain Val Test Train Val TestIEMOCAP 120 31 5810 1623MELD 1038 114 280 9989 1109 2610DailyDialog 11118 1000 1000 87170 8069 7740EmoryNLP 713 99 85 9934 1344 1328Table 1: The statistics of four datasets.",
        "4 Experimental Settings4.1 Implementation DetailsWe conduct hyper-parameter search for our pro-posed DAG-ERC on each dataset by hold-out vali-dation with a validation set. The hyper-parametersto search include learning rate, batch size, dropoutrate, and the number of DAG-ERC layers. For the!that is described in 3.2, we let != 1 for theoverall performance comparison by default, but wereport the results with !varying from 1 to 3 in 5.2.",
        "For other hyper-parameters, the sizes of all hiddenvectors are equal to 300, and the feature size for theRoBERTa extractor is 1024. Each training and test-ing process is run on a single RTX 2080 Ti GPU.",
        "Each training process contains 60 epochs and itcosts at most 50 seconds per epoch. The reportedresults of our implemented models are all based onthe average score of 5 random runs on the test set.",
        "4.2 DatasetsWe evaluate DAG-ERC on four ERC datasets. Thestatistics of them are shown in Table 1.",
        "IEMOCAP (Busso et al., 2008): A multimodalERC dataset. Each conversation in IEMOCAPcomes from the performance based on script bytwo actors. Models are evaluated on the sampleswith 6 types of emotion, namely neutral ,happiness ,sadness ,anger ,frustrated , and excited . Since thisdataset has no validation set, we follow Shen et al.",
        "(2020) to use the last 20 dialogues in the trainingset for validation.",
        "MELD (Poria et al., 2019b): A multimodal ERCdataset collected from the TV show Friends . Thereare 7 emotion labels including neutral ,happiness ,surprise ,sadness ,anger ,disgust , and fear.",
        "DailyDialog (Li et al., 2017): Human-written di-alogs collected from communications of Englishlearners. 7 emotion labels are included: neutral ,happiness ,surprise ,sadness ,anger ,disgust , andfear. Since it has no speaker information, we con-sider utterance turns as speaker turns by default.",
        "EmoryNLP (Zahiri and Choi, 2017): TV showscripts collected from Friends , but varies fromMELD in the choice of scenes and emotion labels.",
        "The emotion labels of this dataset include neutral ,sad,mad,scared ,powerful ,peaceful , and joyful .",
        "We utilize only the textual modality of the abovedatasets for the experiments. For evaluation met-rics, we follow Ishiwatari et al. (2020) and Shenet al. (2020) and choose micro-averaged F1 exclud-ing the majority class (neutral) for DailyDialog andweighted-average F1 for the other datasets.",
        "4.3 Compared MethodsWe compared our model with the following base-lines in our experiments:",
        "Recurrence-based methods: DialogueRNN (Ma-jumder et al., 2019), DialogRNN-RoBERTa(Ghosal et al., 2020), and COSMIC without ex-ternal knowledge3(Ghosal et al., 2020).",
        "Graph-based methods: DialogurGCN (Ghosalet al., 2019), KET (Zhong et al., 2019), DialogXL(Shen et al., 2020) and RGAT (Ishiwatari et al.,2020).",
        "Feature extractor: RoBERTa (Liu et al., 2019).",
        "Previous models with our extracted features:",
        "DialogueGCN-RoBERTa, RGAT-RoBERTa andDAGNN (Thost and Chen, 2021)4.",
        "Ours: DAG-ERC.",
        "5 Results and Analysis5.1 Overall PerformanceThe overall results of all the compared methods onthe four datasets are reported in Table 2. We cannote from the results that our proposed DAG-ERCachieves competitive performances across the fourdatasets and reaches a new state of the art on theIEMOCAP, DailyDialog and EmoryNLP datasets.",
        "As shown in the table, when the feature ex-tracting method is the same, graph-based modelsgenerally outperform recurrence-based models onIEMOCAP, DailyDialog, and EmoryNLP. This phe-nomenon indicates that recurrence-based modelscannot encode the context as effectively as graph-based models, especially for the more importantlocal context. What's more, we see a significantimprovement of DAG-ERC over the graph-based3In this paper, we compare our DAG-ERC with COSMICwithout external knowledge, rather than the complete COS-MIC, in order to make a clearer comparison on the modelarchitecture, even though our DAG-ERC outperforms the com-plete COSMIC on IEMOCAP, DailyDialog and EmoryNLP.",
        "4DAGNN is not originally designed for ERC, so we applyour DAG building method and the extracted feature for it.",
        "models on IEMOCAP, which demonstrates DAG-ERC's superior ability to capture remote informa-tion given that the dialogs in IEMOCAP are muchlonger (almost 70 utterances per dialog).",
        "On MELD, however, we observe that neithergraph-based models nor our DAG-ERC outper-forms the recurrence-based models. After goingthrough the data, we find that due to the data collec-tion method (collected from TV shows), sometimestwo consecutive utterances in MELD are not coher-ent. Under this circumstance, graph-based models'",
        "advantage in encoding context is not that important.",
        "Besides, the graph-based models see consider-able improvements when implemented with thepowerful feature extractor RoBERTa. In spite ofthis, our DAG-ERC consistently outperforms theseimproved graph-based models and DAGNN, con-firming the superiority of the DAG structure andthe effectiveness of the improvements we make tobuild DAG-ERC upon DAGNN.",
        "5.2 Variants of DAG StructureIn this section, we investigate how the structure ofDAG would affect our DAG-ERC's performanceby applying different DAG structures to DAG-ERC.",
        "In addition to our proposed structure, we furtherdefine three kinds of DAG structure: (1) sequence,in which utterances are connected one by one; (2)",
        "DAG with single local information, in which eachutterance only receives local information from itsnearest neighbor, and the remote information re-mains the same as our DAG; (3) common DAG, inwhich each utterance is connected with \u0014previousutterances. Note that if there are only two speakerstaking turns to speak in a dialog, then our DAG isequivalent to common DAG with \u0014= 2!, mak-ing the comparison less meaningful. Therefore, weconduct the experiment on EmoryNLP, where thereare usually multiple speakers in one dialog, and theDAG # Preds F1 scoreSequence 0.92 37.57Single local information 1.66 38.22Common\u0014= 2 1.78 38.30Common\u0014= 4 3.28 38.34Common\u0014= 6 4.50 38.48Ours!= 1 2.69 39.02Ours!= 2 4.46 38.90Ours!= 3 5.65 38.94Table 3: Different DAGs applied to DAG-ERC.",
        "speakers speak in arbitrary order. The test perfor-mances are reported in Table 3, together with theaverage number of each utterance's predecessors.",
        "Several instructive observations can be madefrom the experimental results. Firstly, the per-formance of DAG-ERC drops significantly whenequipped with the sequence structure. Secondly,our proposed DAG structure has the highest perfor-mance among the DAG structures. Considering ourDAG with!= 2and common DAG with \u0014= 6,with very close numbers of predecessors, our DAGstill outperforms the common DAG by a certainmargin. This indicates that the constraints basedon speaker identity and positional relation are ef-fective inductive biases, and the structure of ourDAG is more suitable for the ERC task than rigidlyconnecting each utterance with a fixed number ofpredecessors. Finally, we find that increasing thevalue of!may not contribute to the performanceof our DAG, and != 1tends to be enough.",
        "5.3 Ablation StudyTo study the impact of the modules in DAG-ERC,we evaluate DAG-ERC by removing relation-awarefeature transformation, the nodal information unit,and the contextual information unit individually.",
        "The results are shown in Table 4.",
        "As shown in the table, removing the relation-aware feature transformation causes a sharp per-formance drop on IEMOCAP and DailyDialog,while a slight drop on MELD and EmoryNLP.",
        "Note that there are only two speakers per dialogMethod IEMOCAP MELD DailyDialog EmoryNLPDAG-ERC 68.03 63.65 59.33 39.02w/o rel-trans 64.12 (#3.91) 63.29 (#0.36) 57.12 (#2.21) 38.87 (#0.15)",
        "Table 4: Results of ablation study on the four datasets,with rel-trans ,eH, andCdenoting relation-aware fea-ture transformation, nodal information unit, and con-textual information unit, respectively.",
        "1 2 3 4 5 6 7 8 9 10 11 12# layers636465666768F1 scoreRGAT-RoBERTaDAGNNDAG-ERCFigure 4: Test results of RGAT-RoBERTa, DAGNN,and DAG-ERC on the IEMOCAP dataset by differentnumbers of network layers.",
        "in IEMOCAP and DailyDialog, and there are usu-ally more than two speakers in dialogs of MELDand EmoryNLP. Therefore, we can infer that therelation of whether two utterances have the samespeaker is sufficient for two-speaker dialogs, whilefalls short in the multi-speaker setting.",
        "Moreover, we find that on each dataset, the per-formance drop caused by ablating nodal informa-tion unit is similar to contextual information unit,and all these drops are not that critical. This im-plies that either the nodal information unit or con-textual information unit is effective for the ERCtask, while combining the two of them can yieldfurther performance improvement.",
        "5.4 Number of DAG-ERC LayersAccording to the model structure introduced inSection 3.3.2, the only way for GNNs to receiveinformation from a remote utterance is to stackmany GNN layers. However, it is well knownthat stacking too many GNN layers might causeperformance degradation due to over-smoothing(Kipf and Welling, 2016). We investigate whetherthe same phenomenon would happen when stack-ing many DAG-ERC layers. We conduct an ex-periment on IEMOCAP and plot the test resultby different numbers of layers in Figure 4, withRGAT-RoBERTa and DAGNN as baselines. Asillustrated in the figure, RGAT suffers a significantperformance degradation after the number of lay-ers exceeds 6. While for DAGNN and DAG-ERC,with the number of layers changes, both of theirperformances fluctuate in a relatively narrow range,indicating that over-smoothing tends not to happenin the directed acyclic graph networks.DatasetEmotional shift w/o Emotional shift# Samples Accuracy # Samples AccuracyIEMOCAP 576 57.98% 1002 74.25%MELD 1003 59.02% 861 69.45%DailyDialog 670 57.26% 454 59.25%EmoryNLP 673 37.29% 361 42.10%Table 5: Test accuracy of DAG-ERC on samples withemotional shift and without it.",
        "5.5 Error StudyAfter going through the prediction results on thefour datasets, we find that our DAG-ERC fails todistinguish between similar emotions very well,such as frustrated vsanger ,happiness vsexcited ,scared vsmad, and joyful vspeaceful . This kind ofmistake is also reported by Ghosal et al. (2019). Be-sides, we find that DAG-ERC tends to misclassifysamples of other emotions to neutral on MELD,DailyDialog and EmoryNLP due to the majorityproportion of neutral samples in these datasets.",
        "We also look closely into the emotional shiftissue, which means the emotions of two consecu-tive utterances from the same speaker are different.",
        "Existing ERC models generally work poorly inemotional shift. As shown in Table 5, our DAG-ERC also fails to perform better on the sampleswith emotional shift than that without it, thoughthe performance is still better than previous mod-els. For example, the accuracy of DAG-ERC in thecase of emotional shift is 57.98% on the IEMO-CAP dataset, which is higher than 52.5% achievedby DialogueRNN (Majumder et al., 2019) and 55%achieved by DialogXL (Shen et al., 2020).",
        "6 ConclusionIn this paper, we presented a new idea of mod-eling conversation context with a directed acyclicgraph (DAG) and proposed a directed acyclic graphneural network, namely DAG-ERC, for emotionrecognition in conversation (ERC). Extensive ex-periments were conducted and the results showthat the proposed DAG-ERC achieves compara-ble performance with the baselines. Moreover, bycomprehensive evaluations and ablation study, weconfirmed the superiority of our DAG-ERC and theimpact of its modules. Several conclusions can bedrawn from the empirical results. First, the DAGstructures built from conversations do affect the per-formance of DAG-ERC, and with the constraintson speaker identity and positional relation, the pro-posed DAG structure outperforms its variants. Sec-",
        "ond, the widely utilized graph relation type ofwhether two utterances have the same speaker isinsufficient for multi-speaker conversations. Third,the directed acyclic graph network does not sufferover-smoothing as easily as GNNs when the num-ber of layers increases. Finally, many of the errorsmisjudged by DAG-ERC can be accounted for bysimilar emotions, neutral samples and emotionalshift. These reasons have been partly mentionedin previous works but have yet to be solved, whichare worth further investigation in future work."
    ]
}
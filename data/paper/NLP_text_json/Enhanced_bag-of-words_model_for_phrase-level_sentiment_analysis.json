{
    "Abstract": "-We propose anovel rule-based model toincorporatecontextual information and effect ofnegation that enhances theperformance ofsentiment classification performed using bag-of­words models. Weemployed morphological analysis infeatureextraction toensure feature vector contains only opinionatedwords inatextual review. Also itreduces thedimensionalityoffeature vector and, eventually improves the efficiency oftheclassification algorithm. Further, weconsider grammaticalrelationships toincorporate thecontext ofadjectives and scopeofnegations within aphrase, tothefeature vector. This enablesourmodel tocapture contextual polarity ofadjectives andimpactofnegation words. For themorphological analysis wemainlyemploy Part OfSpeech taggers (POS taggers) and grammaticalrelationships which areobtained using typed dependency parsers.Byusing dependency-based rules, werelax theconditional inde­pendent assumption ofbag-of-words models byway ofcombiningadjectives and negations toidentified target words and, henceobtain asentiment classification accuracy that significantly betterthan baseline performance.Keywords-sentiment analysis, contextual polarity, bag-of­words",
    "Keywords": "-sentiment analysis, contextual polarity, bag-of­words",
    "Body": [
        "INTRODUCTIONThe opportunity tocapture \"what other people think\" usingsocial media data hasraised increasing interest both inthescientific community andinthebusiness world. However, itisaformidable task tocapture opinions andemotions from ever­growing and unstructured textual data. Sentiment Analysisisagrowing research area ofNatural Language Processingwhich aims atidentifying positive andnegative opinions andemotions from atextual data. Presently, Sentiment Analysisresearch works range from document level classification [1]",
        "tosentence-level [2],phrase-level [3]orfeature/aspect levelanalysis [4].",
        "Much previous works onsentiment classification have fo­cused ondocument-level sentiment classification, forexamplemovie review classification by[5].The bag-of-words modelssuch asNaIve Bayes (NB), Support Vector Machine (SVM)",
        "andMaximum Entropy classifiers have been shown toworkwell inbinary positive negative sentiment classification tasksondocument-level datasets such asmovie reviews [5].Pangetal.found theSVM tobethemost accurate classifier in[5].",
        "However, Document-level sentiment classification incorrectlyassumes that subject ofallsentiment issame with thesubject978-1-4799-7732-1/14/$31.00 ©2014 IEEEofa document. Similarly, even sentence level classificationmay suffer from the same due tosentences with mixedsentiment ormultiple subjects. Since ourresearch work isfocused more towards context-aware sentiment classification,our interest mainly lies with phrase-level and aspect-levelsentiment classification. Sentiment analysis atsuch afine­grained level hasproven very useful intasks such asquestionsandanswering systems andsummarisation systems.",
        "Wang andManning in[6]have observed thatsimple NBandSVM variants outperform most published results onsentimentanalysis datasets, sometimes providing anew state-of-art per­formance level. However, Application ofBag-of-Words modelinafine-grained level sentiment analysis leads tolessaccurateresults mainly due totheabsence ofcontextual-polarity andeffect ofnegations. Contextual polarity aims tocapture thesentiment ofaterm relative tothecontext. Also, Asdiscussedin[7]effect ofcontextual information insentiment analysis isvital. Asanexample, hotel reviews may contain \"hot water\",which hasapositive semantic orientation, whereas \"hot room\"",
        "hasanegative orientation [8].Thus contextual polarity plays avital role insentiment classification. Further, Negations termsinasentence may reverse thesentiment ofacertain word. Forexample consider thesentence \"This movie isgood\" versus\"This movie isnotgood\". Inthefirst onegood isapositiveterm and sothis sentence ispositive. When \"not\" isappliedtotheclause, \"good\" isbeing used inanegative context andsothesentence isnegative [9].",
        "The restofthepaper isorganized asfollows. InSection IIwediscuss therelated work. Section III discusses thepro­posed method. Section IVpresent theexperiment set-up andresults. The experimental results areevaluated inSection VandSection VIconcludes ourwork.",
        "II. RELATED WORKMuch work onsentiment analysis classifies documents bytheir overall sentiment, forexample determining whether areview ispositive ornegative [10] [5][1].",
        "Phrase-level and aspect-level sentiment analysis hasbeenofgreat interest from thepast decade because ofitspracticalutility. This involves extracting theaspects andtheassociatedsentiments. Huand Liu [11] formulated this problem andapplied association mining toextract product features andusedAuthorized licensed use limited to: University Town Library of Shenzhen. Downloaded on July 21,2023 at 08:05:25 UTC from IEEE Xplore.  Restrictions apply.",
        "Kasthuriarachchy, B.H., Zoysa, K.D., Premaratne, H.L. 211return (Negated)Algorithm 3.1: ASSIGN NEGATION TARGET(phrase)",
        "Initially allthe occurrences ofnegation terms \"not\",\"n't\"",
        "and\"no\" inaphrase Pareextracted. Then, foreach negationterm neg, wetraverse through allthegrammatical rules inDsearching forneg~ x,where therelationship retis\"neg\". Alltarget words xidentified through such grammaticalrelationships areconsidered tobeinfluenced bythescope ofthenegation. Asanexample, thephrase \"but had nodelphorcutlery\" contains anegation word \"no\" and asshown indodoNegated f-{}",
        "RIf-{\"advmod\",\"amod\"}",
        "R2f-{\"conj_and\",\"conj_or\"}",
        "mods f-{\"not\",\"very\"}",
        "Nf-allnegation words inphraseDf-alldependency rules ofphraseforeach neg ENforeach depRule EDand relE{\"neg\"}",
        "ifnot(x~wIand relERIandxEmods)",
        "{Negated U(neg_+w2)",
        "relthen foreach (wI--+ w2EDandrelER2)",
        "doNegated U(neg_+w2)A.Information ExtractionInitially Parts OfSpeech tagging (POS tagging) isper­formed oneach phrase toextract nouns, verbs, adjectivesandnegation terms. Since, wearenotinterested inintensitylevel ofthesentiment, intensifiers areomitted. Also, whenextracting verbs, acopula orlinking verb \"be\" and allformofthat verb areexcluded. This approach helps toreducethedimensionality ofthefeature space without affecting theclassification accuracy, since most oftheexcluded words havenegligible effect onasentiment orientation.",
        "LetPbethetextual phrase tobeanalysed. Since wegenerate candidate features assequences ofnouns, verbs,adjectives that appear inphrases, weneed totokenize Pandhave toattach part-of-speech information toeach word. Wehave used theStanford POS tagger [12] forthistask. LetFbethesetofwords extracted. Also, weobtain thedependency treeforthePOS tagged phrase using Stanford Typed Dependencyparser [13]. LetDbethesetofalldependency -rules generatedbytheparser. Useofdependency rules inidentifying thescopeofnegation andcontext ofadjectives isdiscussed below.",
        "B.Scope ofNegationWeinvestigate theproblem ofdetermining thepolarity ofsentiments when oneormore occurrences ofanegation termsuch as\"not\" appear inasentence. Wepropose arule-basedapproach toidentify thescope ofnegations toincorporatetheeffect totarget words. Negation may belocal orinvolvelonger distance dependencies. Thus, anon-trivial methodologyisrequired todetermine it.",
        "III. PROPOSED METHODaseed setofadjective expanded using Wordnet synsets toidentify thepolarity ofthesentiment words, butthey donotmake anyattempts torelate theproduct features obtained intoappropriate aspects.",
        "Wu et.al[2]usephrase dependency parsing foropinionmining. Independency grammar, structure isdetermined bytherelation between ahead anditsdependents. Thedependentisamodifier orcomplement and thehead plays amoreimportant role indetermining thebehaviours ofthepair. Theauthors want tocompromise between theinformation loss oftheword level dependency independency parsing asitdoesnotexplicitly provide local structures andsyntactic categoriesofphrases andtheinformation gain inextracting long distancerelations. Hence they extend thedependency tree node withphrases.",
        "Huet.al[3]used frequent item sets toextract themostrelevant features from adomain and pruned ittoobtain asubset offeatures. They extract thenearby adjectives toafeature asanopinion word regarding that feature. Using aseed setoflabeled Adjectives, which they manually developforeach domain, they further expand itusing WordNet andusethem toclassify theextracted opinion words aspositiveornegative.",
        "Wilson etal.[3]evaluate sentence and discourse-basedvalence shifters. They examine 28syntactical and linguisticfeatures inamachine learning approach and usethese fea­tures totrain four different algorithms. Larger corpora yieldsignificantly better results than thebaseline.",
        "Themethod proposed in[2]improves thesentiment classifi­cation ofon-line customer reviews onsentence level unlike theword level lexical feature based work, byfocus onsentences,thisalso concentrate oncontextual information.",
        "Wepropose anovel rule-based model toextract informa­tion andtoincorporate contextual information that enhancestheperformance ofsentiment classification performed usingbag-of-words models. Weemployed morphological analysisinfeature extraction toensure feature vector contains onlyopinionated words inatextual review. Also itreduces thedimensionality offeature vector and, eventually improvestheefficiency ofthe classification algorithm. Further, weconsider grammatical relationships toincorporate thecontextofadjectives and scope ofnegations within aphrase, tothefeature vector. This enables our model tocapture contex­tual polarity ofadjectives and impact ofnegation words.",
        "For themorphological analysis wemainly employ Part OfSpeech taggers (POS taggers) and grammatical relationshipswhich areobtained using typed dependency parsers. Byusingdependency-based rules, werelax theconditional independentassumption ofbag-of-words models byway ofcombiningadjectives andnegations toidentified target words and, henceobtain asentiment classification accuracy that significantlybetter than baseline performance.",
        "2014 International Conference onAdvances inICTforEmerging Regions (ICTer) 11th&12thDecember 2014Authorized licensed use limited to: University Town Library of Shenzhen. Downloaded on July 21,2023 at 08:05:25 UTC from IEEE Xplore.  Restrictions apply.",
        "212Figure 1,relationship between \"no\" and\"delph\"isidentifiedasdescribed above.",
        "cc(had-2, but-I)",
        "root (ROOT-O, had-2)",
        "neg(delph-4, no-3)",
        "dobj (had-2, delph-4)",
        "dobj (had-2, cutlery-6)",
        "conj_or(delph-4, cutlery-6)",
        "Fig. 1.Collapsed Typed Dependencies ofthephrase \"but hadnodelph orcutlery\"",
        "However, not allsuch target words arenegated bytheneg, due tothepresence ofadverbial modifier (advmod) oradjectival modifier (amod). Asanexample thephrase \"Theroom isnotonly good\" bears apositive sentiment despitehaving a\"neg\" relationship between \"not\" and\"good\" asinFigure 2.The word \"good\" isnotnegated bythenegationterm, duetothepresence ofamod \"only\". Thus, ifthere existsagrammatical relationship y~ x,inwhich reiisamod oradvmod andyisaword such as\"only\" or\"very\", such targetwords x,arenotconsidered tobenegated bythecorrespondingnegation term.",
        "Once thetarget terms affected bythenegation areidentified,such words areprefixed with negterm followed bya\"_\".",
        "Further, we considered the conjunct relations \"and\"",
        "(conj_and) and \"or\" (conj_or) topropagate theeffect ofnegations, since such conjunctions expand thescope ofthenegations. Asshown inFigure 1,weidentify theeffect of. conj ornegatIon on\"cutlery\" through delph-4 -) cutlery-6.",
        "nsubj (good-S, room-I)",
        "cop (good-S, is-2)",
        "neg (good-S, not-3)",
        "advrnod(good-S, only-4)",
        "root (ROOT-O, good-S)",
        "Fig. 2.Collapsed Typed Dependencies ofthephrase \"room isnotonly good\"",
        "The process outlined inAlgorithm 3.1was employed toincorporate scope ofnegation tothefeature vector.",
        "C.Contextual PolarityAdjectives inagiven phrase play avital role insentimentclassification. However, polarity ofanadjective highly dependsonthedomain aswell ascontext. Also, anaYve method, likeextracting theNouns closest totheadjective, does notworksowell when thesentence hasmultiple aspects anddistributedemotions.",
        "11th&12thDecember 2014Enhanced Bag-of-Words Model forPhrase-Level Sentiment AnalysisAlgorithm 3.2: ASSIGN ADJECTIVE CONTEXT(phrase)",
        "ContextUnits +--{}",
        "Rl+--{\"nsubj\"}",
        "R2+--{\"ccomp\",\"acomp\"}",
        "R3+--{\"conj_or\",\"conj_and\"}",
        "contexts +--{}",
        "D+--alldependency rules ofphraseforeach adj Ephraseforeach adj~xED and relERldoContext Units U(adj_+x);contexts Uxforeach x~ adj EDand xER2do do Context Units U(adj_+x);contexts Uxforeach cEcontextsdo{for each (c~ w2EDand relER3)",
        "doContextUnits U(negWord_ +w2)",
        "return (ContextU nits)",
        "Inourmodel, insight ofcontextual polarity isadded byconsidering adjectival complement (acomp), clausal comple­ment (ccomp) andnominal subject (nsubj) grammatical rela­tionships generated using Stanford Dependency Parser. Hence,after theinformation extraction step, foreach adjective adjinaphrase, wesearch forgrammatical relationships adj~ y,such thatreiE{\"nsubj\",\"acomp\", \"ccomp\"} inD.Afterwards,each target word yisprefixed with theadjfollowed bya\"_\".",
        "Further, asinnegation scope detection, theconjunct relationsareconsidered toexpand thecontext oftheadjectives.",
        "The process outlined inAlgorithm 3.2was employed toincorporate contextual polarity tothefeature vector.",
        "IV. EXPERIMENTSWeused adata setthat consists of65hotel reviews fromTripAdvisor.com created by[14]. Data setcontains 1541elementary discourse units (EDUs), which were created bysegmenting allsentences using SLESG software package!.",
        "Afterwards, allindividual EDUs were manually annotated by9annotators with thesentiment negative, positive orneutral.",
        "Since allthesentences were segmented, ourdata setconsistsofphrases thatcanbeused forevaluating ourphrase-level sen­timent analysis model. However, since wearenotinterested inanalyzing thesubjectivity ofphrases, wehave only considerednegative andpositive phrases. Thus, ourdata setcontains 1125phrases with 548negative phrases and577positive phrases.",
        "Initially, allthephrases were tokenized into words usingStanford Word Tokenizer andstandard Naive Bayes algorithmwas applied considering each word asafeature. Also, NaYveBayes algorithm was applied after removing stop words andconsidering each word asafeature. Further, inboth theoccasions above bi-gram approach hasalso been considered.",
        "Accuracy ofthese approaches isconsidered asthebaseline forphrase-level sentiment analysis andaccuracy ofourmodel iscompared against thebaseline.",
        "1http://www.sfu.calmtaboadalresearchlSLSeg.html2014 International Conference onAdvances inICTforEmerging Regions (ICTer)"
    ]
}
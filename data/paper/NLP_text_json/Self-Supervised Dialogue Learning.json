{
    "Abstract": "The sequential order of utterances is oftenmeaningful in coherent dialogues, and the or-der changes of utterances could lead to low-quality and incoherent conversations. We con-sider the order information as a crucial su-pervised signal for dialogue learning, which,however, has been neglected by many previ-ous dialogue systems. Therefore, in this pa-per, we introduce a self-supervised learningtask, inconsistent order detection , to explic-itly capture the flow of conversation in dia-logues. Given a sampled utterance pair triple,the task is to predict whether it is ordered ormisordered. Then we propose a sampling-based self-supervised network SSN to per-form the prediction with sampled triple ref-erences from previous dialogue history. Fur-thermore, we design a joint learning frame-work whereSSN can guide the dialogue sys-tems towards more coherent and relevant di-alogue learning through adversarial training.We demonstrate that the proposed methodscan be applied to both open-domain and task-oriented dialogue scenarios, and achieve thenew state-of-the-art performance on the Open-Subtitiles and Movie-Ticket Booking datasets.",
    "Keywords": null,
    "Body": [
        "IntroductionIn recent years, dialogue systems have achievedfruitful results with neural conversation models inboth open-domain generation (Ritter et al., 2011;",
        "Sordoni et al., 2015b; Li et al., 2016b, 2017; Xuet al., 2017; Zhang et al., 2018b) and task-orientedcompletion (Wen et al., 2015, 2017; Williamset al., 2017; Bordes et al., 2017; Su et al., 2018).",
        "These methods empower lots of real-world dia-logue applications such as Google Home and Ap-ple Siri.",
        "However, the utterance generation from di-alogue systems still faces some critical chal-lenges, including utterance blandness and incoher-ence (Gao et al., 2018). They are mainly causedby the objective function of the dialogue systemsthat prefer utterances with unconditionally highprobability (Li et al., 2016a). We argue that ina meaningful and coherent dialogue, the changeof utterance order will lead to a low-quality dia-logue. However, most existing neural-based dia-logue systems either encode the full dialogue his-tory (Li et al., 2017; Xu et al., 2017) or only thecurrent utterance (Liu and Lane, 2018). None ofthem explicitly models the sequential order andstudies its criticality to the dialogue learning prob-lem.",
        "In this paper, we explore the sequential orderwithin the dialogue as the self-supervised signal toguide meaningful and coherent dialogue learning.",
        "We introduce a self-supervised learning task, in-consistent order detection, to explicitly capture theorder signal of the dialogue. The task is definedas, given a target utterance pair triple, the modelis required to predict whether the triple is cor-rectly ordered or not. For instance, the utterancepair tripleh(Q1;A1);(Q4;A4);(Q2;A2)iis mis-ordered. The key to solving this task is to modelthe utterance order based on the dialogue contexteffectively. But when directly encoding the full di-alogue history along the temporal order, the modelactually only focuses on the ending utterances, andearlier information is largely discarded (Li et al.,2017). Thus, we propose a sampling-based self-supervised network (SSN ) to account for theforgetfulness problem and solve the inconsistentorder detection task. In order to accurately predictif a target utterance triple is ordered or not, we ran-domly sample utterance triples from the dialoguehistory as the reference to incorporate the dialoguecontext. Since for the same target utterance triple,the sampled triple references are different at dif-ferent iterations during training. It essentially ap-proximates the full dialogue history without suf-",
        "3858fering from the forgetfulness issue.",
        "To further utilizeSSN in real dialogue learn-ing, we propose to jointly learn SSN and the di-alogue model via alternative training, where theoutput probability of SSN is treated as the ordersignal to evaluate the generated utterance. More-over, the proposed approach can be applied to bothopen-domain and task-oriented dialogue learning,which indicates that SSN is a general and scal-able approach for dialogue learning. Empiricalresults on two widely-used benchmark datasets,OpenSubtitles and Movie-Ticket Booking, showthat our self-supervised network consistently im-proves the state-of-the-art (SOTA) neural-baseddialogue training methods. In summary, our maincontributions are three-fold:",
        "\u000fWe introduce the task of inconsistent or-der detection, and propose a self-supervisedlearning networkSSN to solve this task andexplicitly model the crucial order informationin dialogue.",
        "\u000fWe propose a general framework to jointlylearnSSN and the dialogue models, wherethe sequential order in dialogues can be ex-plicitly used to guide the utterance genera-tion.",
        "\u000fOur method advances the existing state-of-the-art dialogue systems in both open-domainand task-oriented scenarios.",
        "2 Related WorkDialogue Learning Dialogue systems can beroughly classified into open-domain and task-oriented scenarios. In recent years, neural-basedconversation models have shown great power inbuilding dialogue systems (Ritter et al., 2011; Sor-doni et al., 2015b; Vinyals and Le, 2015; Serbanet al., 2016; Luan et al., 2016). However, the utter-ances generated by neural-based dialogue systemsstill suffer from blandness and incoherence (Gaoet al., 2018). To address these problems, Li et al.",
        "(2016a) propose a mutual information objectiveto infer the utterance generation. Serban et al.",
        "(2017) and Zhang et al. (2018a) further apply thelatent variable models to generate more specificresponses. Similar to some language generationtasks (Lamb et al., 2016; Yu et al., 2017), Gen-erative adversarial networks (GAN) (Goodfellowet al., 2014) have also been adapted to learn a bet-ter objective function for the dialogue (Li et al.,2017; Xu et al., 2017; Liu and Lane, 2018; Suet al., 2018). The discriminator in GAN is of-ten used to evaluate the generated utterances andguide dialogue learning. However, these methodsmainly focus on the surface information of gener-ated utterances to guide the dialogue learning, andfail to consider the utterance connection within thedialogue history. In this paper, we focus on the se-quential information of the dialogue and show thatthe unique sequential order in a meaningful andcoherent dialogue contains more useful semanticinformation for dialogue learning.",
        "Self-Supervised Learning Self-supervisedlearning, which aims to train a network on anauxiliary task where ground-truth is obtainedautomatically, has been successfully applied incomputer vision. Many self-supervised tasks havebeen introduced to use non-visual but intrinsicallycorrelated features to guide the visual featurelearning (Doersch et al., 2015; Wang and Gupta,2015; Pathak et al., 2016). As for natural languageprocessing, predicting nearby words (Mikolovet al., 2013b,a) is a self-supervised task to learnword embeddings. The language modeling isanother line of self-supervision where a languagemodel learns to predict the next word given theprevious sequence (Bengio et al., 2003; Dai andLe, 2015; Peters et al., 2018). Recently, Devlinet al. (2019) further proposes two self-supervisedtasks, the masked language model and next sen-tence prediction, to learn sentence embeddings.",
        "Lample and Conneau (2019); Liu et al. (2019)",
        "further extend these two tasks into multi-lingualand multi-task paradigms. Wang et al. (2019)",
        "consider them at the sentence-level for extractivesummarization. Our work is the first to considerthe sequential order as the self-supervised signalin dialogue and we propose the self-supervisedtask of inconsistent order detection towards morecoherent and relevant dialogue learning.",
        "3 MethodsIn this section, we systematically describe how toutilize the internal sequential order of utterancesas self-supervision for dialogue learning. In Sec-tion 3.1, we first introduce the task of inconsis-tent order detection, where the model needs to pre-dict whether one sampled triple of the dialogue iscorrectly ordered or not. We then present an ef-fective sampling-based approach, self-supervisednetwork (SSN ), to learn to capture the important",
        "3859Q1A1Q2A2Qt-1At-1. .QtAtDialogue HistoryCurrent Utterance PairQ1, A1Q2, A2Qt-1, At-1OrderedSamplingQ1, A1Qt-1, At-1Q2, At2MisorderedQ1, A1Qt, AtQt-1, At-1To be predictedUtterance Pair EncoderOrder Reasoning Layer++Concatenation(a) Triple Reference Sampling(b) Inconsistent Order PredictionMulti-layer PerceptronOutput: 1 MisorderedOutput: 0 OrderedFigure 1: The overview of our self-supervised network ( SSN ) for inconsistent order detection. Given a target triplecontaining the current utterance pair (Qt;At)to be predicted, (a) we first sample triple references from previousdialogue historyf(Q1;A1);\u0001\u0001\u0001;(Qt\u00001;At\u00001)gin each iteration. The references can be ordered or misordered.",
        "(b) For each triple, it is transformed into the triple embedding. The concatenation of triple embeddings is fed intoa MLP, and gives the probability based on the current sampling.",
        "order signal and solve this task (see Section 3.2).",
        "In the end, we show in Section 3.3 how SSN cancontribute to both open-domain and task-orienteddialogue learning by modeling the inconsistent or-der detection.",
        "3.1 Inconsistent Order DetectionThe dialogue systems aim at conversing with thehuman in a meaningful and coherent way (Gaoet al., 2018). Thus, the sequential order indialogue data is an important signal for build-ing a good dialogue system. Existing neural-based dialogue systems only consider this sig-nal in a weak and implicit way, where they usehierarchical encoders to model the dialogue his-tory (Sordoni et al., 2015a; Serban et al., 2016;",
        "Li et al., 2017; Serban et al., 2017; Xing et al.,2018). However, we argue that these methodsare mainly designed to model the overall seman-tic context information of the dialogue historybut not good at modeling intermediate sequen-tial order. Especially, the order signal is becom-ing weak as the number of dialogue turns in-creases. Thus, we propose the task of inconsis-tent order detection to force building models tocapture this signal as self-supervision explicitly.",
        "Given a dialogue till the turn t, we can formulateit asf(Q1;A1);(Q2;A2);\u0001\u0001\u0001;(Qt;At)g, where(Qt;At)is a pair of human-machine utterances.",
        "Then we can sample multiple triples of this dia-logue as utterance pair triples using the followingstrategies:",
        "\u000fOrdered triple sampling : We sample atriple following the dialogue sequential or-der ash(Qi;Ai);(Qj;Aj);(Qk;Ak)i, wherei<j <k\u0014t.",
        "\u000fMisordered triple sampling : The three ut-terance pairs are sampled in a triple ash(Qi;Ai);(Qk;Ak);(Qj;Aj)i, wherei <j <k\u0014t.",
        "Note that when the current dialogue length t <=2, it is not enough to get a rational sampling forutterance pair triples. Thus, we add three ex-tra shared padding utterance pairs (Q\u00002;A\u00002),(Q\u00001;A\u00001)and(Q0;A0)ahead of all the dia-logue data before sampling1.",
        "Based on above triple sampling strate-gies, we define the task of inconsistent or-der detection as: given a dialogue historyf(Q1;A1);(Q2;A2);\u0001\u0001\u0001;(Qt;At)g and thetarget utterance pair (Qt;At)for evaluation, themodel needs to predict whether the sampled tripleTcontaining (Qt;At)is ordered or not . For in-stance,h(Q1;A1);(Q2;A2);(Qt;At)iis ordered(output: 0), while h(Q1;A1);(Qt;At);(Q2;A2)iis misordered (output: 1).",
        "1Specifically, e.g., for the added padding utterance Q\u00002,it is represented as a sequence of one same padding wordfw(Q\u00002)",
        "Ng, whereNis the rounded-up averaged length of utterances in the dataset.",
        "38603.2 Self-Supervised Network SSNWe plan to build the model to solve the inconsis-tent order detection task, and explicitly capture thesequential order in dialogue. The overview of ourapproach is shown in Figure 1. At each dialogueturnt, given a target triple containing the currentutterance pair, we first sample triple referencesfrom the previous dialogue history to capture moresemantic context in dialogue. The target triple andtriple references are then transformed into embed-dings using an utterance pair encoder and an orderreasoning layer. Finally, the concatenation of em-beddings is used for the final prediction. We thendescribe theSSN in detail as follows.",
        "3.2.1 Triple Reference SamplingGiven the task definition in Section 3.1, the modelneeds to predict whether there is inconsistent or-der in the target triple containing the current utter-ance pair (Qt;At). It is intuitive that if we can getmore previous dialogue history, we may make abetter prediction for inconsistent order. One trivialway is to encode the full previous dialogue historyusing a hierarchical network and make the predic-tion. However, Li et al. (2017) suggests that thisstructure actually focuses more on the final twopreceding utterances instead of the whole history.",
        "The sequential order signal is very weak in thiscondition. We also report some similar results inSection 4.1.",
        "Therefore, we propose a sampling-based ap-proach to model the utterance order based onthe dialogue context effectively. For each sam-pling operation, we sample two triple referencesT0andT00from the previous dialogue historyf(Q1;A1);(Q2;A2);\u0001\u0001\u0001;(Qt\u00001;At\u00001)gfollow-ing the sampling strategies in Section 3.1. In gen-eral, we explore the following three combinationsof reference sampling strategies for T0andT00:",
        "\u000fT0andT00are sampled ordered references.",
        "\u000fT0andT00are sampled misordered ones.",
        "\u000fT0is ordered while T00is misordered.",
        "Note that in our experiments, we choose one cer-tain combination and keep using it for samplingthe triple references for all the target triples.",
        "3.2.2 Objective FunctionGiven the target triple embedding Tand thetriple reference embedding T0andT00, we useSSN to calculate the probability p(TjT0;T00) =SSN (T;T0;T00). We use the Binary Cross En-tropy loss to train the model:",
        "whereyis the ground-truth label.",
        "Considering that for the same target triple T, thetriple references are sampled mtimes to approxi-mate the full dialogue history. Then we can rewritethe loss function asL=\u0000E(1mmXi=1ylog(p(i)(TjT(i)0;T(i)00)));(2)",
        "whereT(i)0;T(i)00are the triple references of i-thsampling. This is essentially a Monte Carlo es-timation and the model would effectively incor-porate the dialogue context and capture the orderinformation, avoiding from directly encoding thefull dialogue history and the forgetfulness issue.",
        "3.2.3 Network StructureIn this section, we demonstrate how SSN embedsboth the target triple Tand triple reference T0andT00to generatep(TjT0;T00)in each sampling.",
        "Utterance Pair Encoder First, given a utter-ance pair (Qt;At), we concatenate the QtandAtas one sequence. The sequence is then fed intoa bidirectional long short-term memory network(LSTM) (Hochreiter and Schmidhuber, 1997), andthe utterance pair embedding Utis the concatena-tion of the final two states of the bi-LSTM:",
        "whereNtis the length of the concatenated utter-ance sequence.",
        "Order Reasoning Layer After obtaining the ut-terance pair embeddings (Ui;Uj;Uk)of a sam-pled tripleT=<(Qi;Ai);(Qj;Aj);(Qk;Ak)>,we need to reason and predict whether there is in-consistent order or not. To simplify our model,we use a 3-step reasoning bi-LSTM with the max-pooling layer to perform the order reasoning:",
        "max-pooling ( \u0000h1; \u0000h2; \u0000h3)",
        "where the input of each time step in bi-LSTM isone utterance pairs embedding, and Tis the finalembedding of the given triple.",
        "3861Given the target triple embedding Tand thetriple reference embedding T0andT00, the con-catenation of these three embeddings is fed intoa multi-layer perceptron, returning the probabilityp(TjT0;T00)of the triple is ordered (approaching0) or misordered (approaching 1).",
        "3.3 Self-Supervised Network for DialogueIn this section, we explain how the SSN canbe applied to the current dialogue system in bothopen-domain and task-oriented scenarios.",
        "Suppose we have a dialogue system the the his-toryf(Q1;A1);\u0001\u0001\u0001;(Qt\u00001;At\u00001)g, at turnt, thesystem generate the utterance Atbased on the Qt.",
        "We can sample a misordered target triple Tcon-taining (Qt;At). Following the assumption thatthe sequential order in a meaningful and coher-ent dialogue should be unique, the SSN will beeasy to detect the inconsistent order in Tif thegeneratedAtis good. Otherwise, the Atmaybe of low quality. Therefore, we take a two-stepsampling approach to evaluate the generated ut-teranceAtusingSSN . First, a misordered tar-get tripleTcontaining (Qt;At)is sampled. Thenwe further sample triple references T0andT00asin Section 3.2.1 and how easily the misorder inthe sampled Tcan be detected is measured asET0;T00(p(TjT0;T00). Based on the generated ut-teranceAt, we can sample multiple misordered T,and we set the following expectation to measurethe probability that Atis a good generated utter-ance:",
        "p\u0003SSN =EmisorderedTET0;T00(p(TjT0;T00)):(5)",
        "In this way, we can view human-generated ut-terances as good ones, and machine-generated ut-terances as bad ones. Then we can use the adver-sarial training methods (Goodfellow et al., 2014;",
        "Li et al., 2017; Xu et al., 2017; Su et al., 2018) totrain the dialogue system, where SSN can giveclear order-based signal to guide the generator Gin the system. The framework of using SSN withthe two-step sampling in real dialogue systems areshown in Figure 2. The objective function then canbe formulated as:",
        "min\u0012Gmax\u0012SSNEreal[logp\u0003SSN(x)]",
        "where\u0012Gand\u0012SSN are the parameters ofthe generator GandSSN in the dialogueDialogue SystemSelf-Supervised NetworkDialogue HistoryGenerated UtteranceMisordered Target TripleSignalSamplingTriple ReferencesSamplingFigure 2: The general framework for dialogue learningwith self-supervised network.",
        "systems separately. The xstands for realhuman-generated utterances, which G(:)repre-sents machine-generated ones. The GandSSNare alternately updated during training. We fur-ther describe the details in open-domain and task-oriented scenarios separately.",
        "3.3.1 Open-Domain Dialogue LearningThe open-domain dialogue task is, given a di-alogue history consisting of a sequence of di-alogue utterances f(Q1;A1);:::; (Qt\u00001;At\u00001)g,and currentQt, the model needs to generate a re-sponse utterance At. We consider the adversarialtraining (Li et al., 2017; Xu et al., 2017) for di-alogue generation systems. Following the previ-ous approach (Vinyals and Le, 2015; Serban et al.,2016; Luan et al., 2016; Li et al., 2017), we usethe S EQ2SEQmodel for response generation asthe generator G. The S EQ2SEQfirst transformsthe dialogue history into an embedding using anencoder recurrent network. Conditioned on thehistory embedding, another decoder recurrent net-work then computes the probability of tokens ateach generation step of the response using a soft-max function.",
        "As for the discriminator D, in previous meth-ods, the discriminator directly takes the responseutteranceAtwith or without the full dialogue his-tory, and predicts whether it is human-generated(output: 1) or machine-generated (output: 0). Theprobability of being human-generated is set as thereward to update the Gusing the REINFORCE al-gorithm (Williams, 1992). As for our SSN , therewardRis set asR=p\u0003SSN.",
        "3.3.2 Task-Oriented Dialogue LearningThe task-oriented dialogue, usually formulated asa reinforcement learning problem, aims to build a",
        "3862dialogue agent to interact with real users and learnthe policy to complete the slot-filling task (Juraf-sky and Martin, 2014). While the real-user inter-action is expensive and time-consuming, in thisscenario, the dialogue systems are often trainedwith user simulators (Schatzmann et al., 2006; Liet al., 2016c). However, due to the complexity ofreal conversations and biases in the design of usersimulators, the quality of simulated utterances isunstable. Su et al. (2018) propose an adversariallearning approach to differentiate simulated expe-rience from real experience. Following the sim-ilar assumption that real-user interactions shouldbe meaningful and coherent, we implement ourSSN instead of the conventional discriminator Dto select high-quality stimulated utterances in thetask-oriented dialogue systems.",
        "In this scenario, the generator Gis the worldmodel which produces simulated user experience,and theSSN focuses on scoring the simulateduser experience Qtduring the training process.",
        "Thus, instead of sampling and encoding utterancepairs (Qt;At), here we only use the user utteranceQtinSSN . We keep other parts of the SSNremain the same as in Section 3.2. Because theworld model Gis updated using the multi-tasklearning without the reward from the SSN , theobjective function of the SSN in Equation 6 canbe rewritten as the following during the mini-batchtraining:",
        "wherebrepresents the batch size.",
        "4 Experiments4.1 Intrinsic EvaluationBefore we deploy the self-supervised network intoreal dialogue systems, we first test the model ar-chitectures for reliability. We randomly choose40Kbalanced ordered and misordered utterancepair triples from the OpenSubtitles (Tiedemann,2009) dataset, and train the SSN to solve this 2-class classification. We sample another 1Kbal-anced triples for testing. We also consider a base-line model, where the target triple is encoded bySSN , and the previous dialogue history is en-coded by a hierarchical LSTM. The concatenationof two embeddings is used for the final predic-tion. Because our SSN is a sampling-based ap-Reference Strategy of SSN Average AccuracyAll history by hierarchical LSTM :694 (:006)",
        "2*Ordered Refers :740 (:031)",
        "2*misordered Refers :744 (:029)",
        "1*Ordered + 1*misordered Refers :856 (:017)",
        "Table 1: The intrinsic evaluation results. The num-bers in brackets stand for deviation. Refers: ReferenceTriples.",
        "proach, we report the average prediction accuracyof5runs on the 2-class classification as shown inTable 1.",
        "From the results, we can observe that: (1) Theconventional hierarchical LSTM is not suitable forthis task, and this baseline only shows a marginalimprovement compared with the strategy that onlyconsiders target triple without any history. The re-sults also match previous findings (Li et al., 2017),where they suggest that only the last two proceed-ing utterances in the hierarchical network are se-mantically significant. (2) As for our SSN , it issafe to tell that reference triples can be a tremen-dous supplement to the inconsistent order detec-tion. It is not surprising because by adding refer-ence triples, theSSN will know more informa-tion of semantic context within the dialogue. Es-pecially when having both ordered and misorderedreferences, theSSN has the highest classificationaccuracy. This also shows that the sampling strat-egy, 1*Ordered + 1*misordered references, is themost reliable structure for real dialogue systems.",
        "Thus, for the rest of the experiments, we directlyuse theSSN with one ordered and one misor-dered references strategy to achieve the best per-formance.",
        "4.2 Open-Domain Dialogue LearningDataset Following the previous studies (Vinyalsand Le, 2015; Li et al., 2017; Xu et al., 2017),we choose the widely-used OpenSubtitles (Tiede-mann, 2009) dataset to evaluate different methods.",
        "The OpenSubtitles dataset contains movie scriptsorganized by characters, where we follow Li et al.",
        "(2016b) to retain subtitles containing 5-50 words.",
        "Baselines We consider the following two pop-ular adversarial methods for dialogue learning asthe baselines:",
        "\u000fREGS (Li et al., 2017): The discriminator Dtakes the full dialogue history by a hierarchi-",
        "3863SeparatedG/D D -REGSD-AELD-SSNG-REGS :094:087:041G-AEL :146:128:093G-SSN :203:185:162Table 2: The cross evaluation of adversarial successrate on different generators and discriminators. Pleaserefer to Section 4.2 Adversarial Evaluation for expla-nations.",
        "Model distinct-1 distinct-2REGS 0:0217 0 :0695AEL 0:0311 0 :0948SSN 0:0393 0 :1126Table 3: The automatic evaluation of generated utter-ances on distinct-1 and distinct-2 metrics. Please referto Section 4.2 Automatic Evaluation for explanations.",
        "cal LSTM, and the Monte Carlo search is im-plemented to obtain rewards for every gener-ation step to update the generator G.",
        "\u000fAEL (Xu et al., 2017): The discriminator Donly encodes the currently generated utter-ance by a CNN model and the generator Gisoptimized using an approximate embeddinglayer.",
        "Implementation Details We follow the most ofparameters in Li et al. (2017); Xu et al. (2017) tomake a fair comparison. For the generator modelG, we adopt the same S EQ2SEQmodel (Sutskeveret al., 2014) with an attention mechanism (Bah-danau et al., 2015; Luong et al., 2015) for our ap-proach and baselines. We approximate the dia-logue history for Gusing the concatenation of twopreceding utterances following the Li et al. (2017).",
        "To train the generator G, we use the REINFORCEalgorithm (Williams, 1992) to maximize the ex-pected reward of generated utterances. We alsoimplement the Monte Carlo search to give rewardsfor each generation step. To accelerate the sam-pling process, we use multiple GPUs to parallelizeand distribute the jobs. As for the SSN , it firstgets pre-trained using sampled data from Open-Subtitiles, and then iteratively updated during themin-max adversarial training process. The dimen-sion of the utterance embeddings is 128. The hid-den size is 256for utterance encoding bi-LSTMand1024 for triple reasoning bi-LSTM. The MLPhas a single hidden layer of size 512.Win REGS AELSSNSingle-turn Percentage :095:192:713Multi-turn Percentage :025:171:804Table 4: The human evaluation of generated utterancesin three methods. The result here is statistically signif-icant withp<0:01according to sign test. Please referto Section 4.2 Human Evaluation for explanations.",
        "Adversarial Evaluation Here we use adversar-ial success rate (AdverSuc), which is the fractionof instances where a Gis capable of fooling theD, to evaluate different methods. Higher valuesof AdverSuc for a dialogue system usually lead toa better response generator. After training three(G;D )using REGS, AEL and SSN , we sample4Kdialogue history and use three trained gen-erators to generate response utterances. Thesemachine-generated utterances are then fed intothree trained discriminators to see if they are in-distinguishable from human-generated ones. Thecross evaluation of AdverSuc is shown in Table 2.",
        "From the results, we can observe that: (1)",
        "Our trained generator achieve higher AdverSuc inthree discriminators, which shows that the gener-ator in our approach can generate more human-like utterance responses. (2) The generators ofthe other two methods have a noticeable drop inAdverSuc when evaluating on our SSN -baseddiscriminator. This demonstrates that our self-supervised policy for discriminating utterances issuccessful. (3) The REGS method with full di-alogue history encoded performs worse than theAEL that only considers the current utterances.",
        "We think this indicates that without explicitly stat-ing the guiding signal, both the generator and thediscriminator can be lost about figuring out a goodobjective function during the training process evenwhen encoding the full history.",
        "Automatic Evaluation For automatic evalua-tions, we use the two commonly accepted met-rics distinct-1 and distinct-2. The distinct-1 anddistinct-2, proposed by Li et al. (2016a), are twoways to measure the degree of diversity by cal-culating the number of distinct unigrams and bi-grams in the generated response utterances. Theevaluation results are reported in Table 3. Theresults show that based on the distinct-1 anddistinct-2 metrics, the generator trained in our ap-proach can generate relatively more diverse re-sponses. The results are attractive considering that",
        "3864AgentPlanningStepsEpoch 100 Epoch 200 Epoch 300Succ Reward Turns Succ Reward Turns Succ Reward TurnsD3Q5.7467 43.59 14.03 .6800 34.64 15.92 .7200 40.85 13.11D3Q-SSN .7600 45.71 13.52 .7400 42.93 14.80 .7633 46.16 15.24D3Q (fixed\u0012D) .6800 33.86 17.48 .7000 36.57 16.85 .6933 35.67 17.06D3Q-SSN (fixed\u0012SSN ) .6633 32.04 16.21 .7133 36.71 17.74 .7067 36.03 12.91D3Q10.6333 28.99 16.01 .7000 37.24 15.52 .6667 33.09 15.83D3Q-SSN .7800 48.71 15.84 .8733 56.15 19.57 .8067 50.29 16.48D3Q (fixed\u0012D) .7133 36.36 20.48 .8400 54.87 20.48 .7400 42.89 13.81D3Q-SSN (fixed\u0012SSN ) .7367 42.30 14.79 .8300 52.92 18.16 .7933 48.05 13.73Table 5: The experimental results of different dialogue agents at training epoch = f100;200;300g. Each numberis averaged over 3 runs, and each run tested on 50 dialogues. The D3Q- SSN denotes the D3Q agent where ourproposedSSN replaces the discriminator. The “fixed \u0012D=\u0012SSN ” indicates the discriminator/ SSN is pre-trainedand fixed during the training process. Succ: Success Rate. Reward: Average Reward. Turns: Average Turns.",
        "we do not explicitly use a diversity-guided objec-tive function during the training process. We thinkthe reason is that the diverse utterances are eas-ier to reserve the order information. In previousmethods, the discriminator Donly gives good orbad signals to response generator G, and theGhasto figure out what is an acceptable response by it-self. As for ourSSN , it explicitly forces the Gtogenerate responses that will have unique orders indialogue, which leads to more diverse utterances.",
        "Human Evaluation For human evaluation, wefollow protocols in Li et al. (2016a) and employ-ing crowd-sourced judges from the Amazon Me-chanical Turk to evaluate a random sample of 1000unique generated utterances from three generatorsin the OpenSubtitles test dataset. We present boththe input dialogue history and the generated re-sponses to 5 judges and ask them to decide whichone of the three results is the be.ts Ties are not per-mitted. We consider both single-turn and multi-turn for the evaluation. The results are shown inTable 4. Evidently, the generator trained in ourmethod shows a significant improvement in thequality of generated sentences. The gain is evenhigher in the multi-turn setting than the single-turnsetting. This is because when only considering thesingle-turn dialogue, the information encoded inthree methods will be similar.",
        "4.3 Task-Oriented Dialogue LearningDataset Following the previous work (Penget al., 2018; Su et al., 2018), we use the sameMovie-Ticket Booking dataset collected fromAmazon Mechanical Turk for evaluation. Thedataset is manually labeled based on a schema de-fined by domain experts consisting of 11intentsand16slots in the full domain setting. In total, thedataset has 280annotated dialogues with an aver-age length of approximately 11 turns. In this sce-nario, the goal of dialogue systems is to help theuser complete the tasks through the conversation.",
        "Baselines We compare our SSN -based dis-criminator within the state-of-the-art task-orienteddialogue policy learning approach, DiscriminativeDeep Dyna-Q (D3Q) (Su et al., 2018). At eachturn, the D3Q agent takes Splanning steps inter-acting with the simulator and store stimulated userexperiences based on the scoring of the discrimi-nator. The stimulated user experiences are gener-ated by the world model, which can be viewed asthe generator Gin our case. We replace the con-ventional discriminator Dof D3Q with ourSSN .",
        "Implementation Details For a fair comparison,we remain most of the parameters in the D3Q al-gorithm the same as in Su et al. (2018). In theself-supervised network, the dimension of the ut-terance embeddings is 80. The hidden size is 128for utterance encoding bi-LSTM and 512for triplereasoning bi-LSTM. The MLP has a single hiddenlayer of size 128. We use the simulator2as in Liet al. (2016c) to generate user utterances, and thethreshold interval is set to a range between 0:45and0:55.",
        "Results The experimental results of differentagents at training epoch are shown in Table 5.",
        "From the results, we can observe that: (1) TheD3Q-SSN outperform the D3Q in the most ofcases, which shows that our SSN -based dis-criminator can improve the ability to recognize2https://github.com/MiuLab/TC-Bot",
        "3865the high-quality stimulated user experiences. (2)",
        "When the planning step increases in D3Q, the per-formance shows an apparent drop. This is be-cause the discriminator Din the original D3Qagent keeps lots of low-quality stimulated userexperiences, which significantly degrade the per-formance of the D3Q agent. As for our SSN ,we can see some performance improvement evenwhen using 10-step planning. This substantiallymeans that ourSSN has a better ability to selectthe good simulated user experiences, especially inthe multi-turn dialogue cases."
    ]
}